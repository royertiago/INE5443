\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{graphicx}

\author{Tiago Royer}
\title{Instance Based Learning}

\newcommand{\kNN}{k\mathit{NN}}

\begin{document}

\maketitle

\section{Introdução}

Os algoritmos IBL (\emph{Instance Based Learning})
são uma coleção de algoritmos simbólicos
que classificam instâncias baseados num conjunto de treinamento.
Ao contrário de usar apenas $\kNN$,
os algoritmos IBL tentam identificar apenas os aspectos mais relevantes
do conjunto de treinamento,
simultaneamente reduzindo o tamanho do descritor conceitual
e tolerando ruído na entrada.

Este relatório descreve como e quais algoritmos foram implementados
e discute alguns resultados.

\section{Estrutura do Repositório}

Este repositório é um conjunto de ferramentas de linha de comando
que trabalham com datasets. Há programas para visualização,
geração, e classificação de dados a partir destes datasets.

A maior parte dos programas precisa ser compilada.
O makefile do repositório está configurado
para respeitar a variável \texttt{CXXFLAGS},
portanto os programas do repositório pode ser compilado com
\begin{verbatim}
    $ CXXFLAGS=-O2 make
\end{verbatim}

Todos os programas suportam a opção \verb|--help| na linha de comando.

\subsection{Arquivos \texttt{.data}}

Estes são os conjuntos de dados utilizados pelos programas deste repositório.
São arquivos de texto com uma estrutura específica,
que está detalhada no arquivo \verb|datasets/format.md|.
A maior parte dos programas ou leem datasets da entrada padrão
ou geram conjuntos de dados para a entrada padrão.
(A exceção é o \verb|classify|, em que o conjunto de dados
deve ser especificado na linha de comando através da opção \verb|--dataset|.)

O repositório vem com dois conjuntos de dados prontos.
O primeiro, \verb|datasets/iris.data|,
é o conhecido conjunto de dados de flores do gênero \emph{Iris}%
\footnote{
    \texttt{http://en.wikipedia.org/wiki/Iris\_flower\_data\_set}.
}.
O segundo, \verb|datasets/enclave.data|,
pode ser visto na figura \ref{enclave}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{enclave.png}
    \caption{Conjunto de dados \texttt{datasets/enclave.data}.}
    \label{enclave}
\end{figure}

Existem também dois programas para gerar conjuntos de dados.

\texttt{datatools/generate\_spiral} gera espirais bidimensionais.
O programa permite controlar parâmetros como o número de espirais geradas.

\texttt{pixel\_chooser --generate-dataset --blank 500 500} abre uma janela em branco,
de 500 por 500 pixels, e espera que o usuário clique em algumas posições.
As posições clicadas virarão os pontos no conjunto de dados.
Apertando barra de espaço, a classe dos pontos é alterada;
apertanto qualquer outra tecla encerra o programa e imprime o conjunto gerado.
(Foi assim que foi construído o conjunto \texttt{enclave.data}.)

\section{Programas para classificação de dados}

Apenas dois programas no repositório lidam diretamente com IBL.
O programa \texttt{ibl}, na raíz do repositório,
exibe uma janela dividida em três telas.
A primeira mostra o dataset de entrada;
a segunda mostra o descritor conceitual restante após rodar o algoritmo IBL,
e a última mostra as áreas de influência do descritor conceitual.

O programa \texttt{ibl} permite apenas visualizar
o resultado da execução dos algoritmos IBL.
Entretanto, ele não permite classificar novos pontos
usando o descritor conceitual gerado.
O programa \texttt{classify} é o oposto disso:
ele não possui nenhuma funcionalidade de visualização
(ele funciona em modo \emph{batch}),
mas permite que novas instâncias sejam classificadas
contra o descritor conceitual resultante.

Todas as opções da linha de comando do \texttt{ibl}
são aplicáveis a \emph{classify}, portanto iremos descrevê-las apenas no primeiro.

Para rodar um exemplo com IBL 2, podemos executar
\begin{verbatim}
    $ ./ibl --ibl 2 --shuffle --noise 10 < datasets/enclave.data
    --shuffle-seed 3456 --noise-seed 13456
\end{verbatim}
O programa deve reportar, na saída padrão, 245 acertos e 65 erros,
e exibir a imagem \ref{iblimg}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.3]{ibl.png}
    \caption{Execução de IBL 2 no conjunto de dados \texttt{enclave.data}.}
    \label{iblimg}
\end{figure}

\section{Algoritmos implementados --- IBL 1 e 2}

Estes dois algoritmos são simples e não possuem parâmetros adicionais;
basta escolher \texttt{--ibl 1} ou \texttt{--ibl 2} na linha de comando.

Como o IBL 2 armazena apenas as instâncias para as quais a classificação for incorreta,
o descritor conceitual gerado é significativamente menor do que o gerado pelo IBL 1.
A etapa mais pesada de execução do programa \texttt{ibl},
a geração das áreas de influência do descritor conceitual,
nos permite perceber a diferença de tempo;
com IBL 1, o tempo de execução do programa fica aproximadamente 5 vezes maior.

Entretanto, o IBL 1 possui maior resistência a ruídos do que o IBL 2;
executando o mesmo experimento do exemplo com IBL 1,
podemos ver que a região verde gerada é mais regular do que a gerada com IBL 2.

\section{Algoritmos implementados --- IBL 3 e 4}

Estes dois algoritmos são mais complexos e possuem três parâmetros adicionais.

Os parâmetros $z$ dos intervalos de precisão e intervalos de instância
podem ser especificados separadamente para aceitação e rejeição.
Para alterar a aceitação para \texttt{0.8}, por exemplo,
use \texttt{--accept-threshold 0.8}.
Para colorar a rejeição em \texttt{0.5},
use \texttt{--reject-threshold 0.5}.

Além disso, em alguns casos, IBL 3 e 4 tomam decisões aleatórias.
A semente do gerador de números aleatórios usada pode ser configurada com
\texttt{--ibl-seed <number>}.

Por exemplo, podemos executar
\begin{verbatim}
$ ./ibl --ibl 3 --shuffle --noise 10 < datasets/enclave.data
--shuffle-seed 3456 --noise-seed 13456 --ibl-seed 789
\end{verbatim}

Esta execução do algoritmo mostra que o IBL 3 figura como um intermediário
entre IBL 1 e IBL 2. O descritor conceitual resultante teve o dobro do tamanho
em relação à execução com IBL 2, mas ele se mostrou muito
superior com relação ao ruído introduzido.
De fato, ele superou até o IBL 1, que trabalha com a entrada inteira.

Nos experimentos, notei que a variação dos parâmetros $z$
teve pouca influência nos descritores conceituais,
em relação à influência de trocar de IBL 1 para IBL 3 ou IBL 4.
No exemplo anterior, baixando o \texttt{--reject-threshold} para 0.7
eliminou um dos pontos que acumulava bastante ruído,
mas baixá-lo para 0.5 introduziu outro ponto ruim no descritor conceitual.

Como a maior parte dos conjuntos de dados que utilizei já eram normalizados,
IBL 4 mostrou desempenho praticamente idêntico ao IBL 3.

IBL 5 não foi implementado porquê o código que eu programei não suporta
nem a inserção de novos atributos nem é capaz de representar atributos ausentes,
e é justamente para esses casos que o IBL 5 foi pensado.

\end{document}
